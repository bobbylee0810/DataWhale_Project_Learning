{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 论文种类预测（文本分类）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 数据预处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 数据读取  \n",
    "- 为方便处理，随机抽样10%的数据进行分析"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns #用于画图\n",
    "from bs4 import BeautifulSoup #用于爬取arxiv的数据\n",
    "import re #用于正则表达式，匹配字符串的模式\n",
    "import requests #用于网络连接，发送网络请求，使用域名获取对应信息\n",
    "import json #读取数据，我们的数据为json格式的\n",
    "import pandas as pd #数据处理，数据分析\n",
    "import matplotlib.pyplot as plt #画图工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readArxivFile(path, columns=['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi',\n",
    "       'report-no', 'categories', 'license', 'abstract', 'versions',\n",
    "       'update_date', 'authors_parsed'], count=None):\n",
    "    '''\n",
    "    定义读取文件的函数\n",
    "        path: 文件路径\n",
    "        columns: 需要选择的列\n",
    "        count: 读取行数\n",
    "    '''\n",
    "    \n",
    "    data  = []\n",
    "    with open(path, 'r') as f: \n",
    "        for idx, line in enumerate(f): \n",
    "            if idx == count:\n",
    "                break\n",
    "                \n",
    "            d = json.loads(line)\n",
    "            d = {col : d[col] for col in columns}\n",
    "            data.append(d)\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    return data\n",
    "\n",
    "data = readArxivFile('D:\\code\\Github\\data\\AcademicTrendsAnalysis/arxiv-metadata-oai-snapshot.json', \n",
    "                     ['id', 'title', 'categories', 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(179691, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data = data.sample(frac = 0.1)\n",
    "data.shape"
   ]
  },
  {
   "source": [
    "## 文本提取"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并title和abtraact\n",
    "data['text'] = data['title'] + data['abstract']\n",
    "#将换行符替换位空格\n",
    "data['text'] = data['text'].str.replace('\\n',' ')\n",
    "# 将大写全部转换成小写\n",
    "data['text'] = data['text'].str.lower()\n",
    "# 删除多余列\n",
    "data = data.drop(['abstract','title'],axis = 1) "
   ]
  },
  {
   "source": [
    "## 类别转换"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2  0704.0003  The evolution of the Earth-Moon system based o...   \n",
       "\n",
       "         categories                                           abstract  \\\n",
       "0          [hep-ph]    A fully differential calculation in perturba...   \n",
       "1  [math.CO, cs.CG]    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2  [physics.gen-ph]    The evolution of Earth-Moon system is descri...   \n",
       "\n",
       "  categories_big  \n",
       "0       [hep-ph]  \n",
       "1     [math, cs]  \n",
       "2      [physics]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>categories</th>\n      <th>abstract</th>\n      <th>categories_big</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0704.0001</td>\n      <td>Calculation of prompt diphoton production cros...</td>\n      <td>[hep-ph]</td>\n      <td>A fully differential calculation in perturba...</td>\n      <td>[hep-ph]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0704.0002</td>\n      <td>Sparsity-certifying Graph Decompositions</td>\n      <td>[math.CO, cs.CG]</td>\n      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n      <td>[math, cs]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0704.0003</td>\n      <td>The evolution of the Earth-Moon system based o...</td>\n      <td>[physics.gen-ph]</td>\n      <td>The evolution of Earth-Moon system is descri...</td>\n      <td>[physics]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data['categories'] = data.categories.str.split(' ')\n",
    "data['categories_big'] = data.categories.apply(lambda x : [xx.split('.')[0] for xx in x])\n",
    "data.head(3)"
   ]
  },
  {
   "source": [
    "## 将目标数据（论文大类）二值化  \n",
    "- MultiLabelBinarizer的使用方法[链接](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html)  \n",
    "\n",
    "- 类似于One-Hot编码，只不过自变量可以是元组或列表"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "data_label = mlb.fit_transform(data.categories_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(179691, 38)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data_label.shape"
   ]
  },
  {
   "source": [
    "# TF-IDF+机器学习分类器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 分词  \n",
    "- TfidfVectorizer简介：[链接](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)  \n",
    "- 将原始句子转换成词频向量"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "vecter = TfidfVectorizer(max_features=4000)\n",
    "data_tfidf = vecter.fit_transform(data.text)"
   ]
  },
  {
   "source": [
    "## 数据集划分"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 训练集划分  \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_tfidf,data_label)\n"
   ]
  },
  {
   "source": [
    "## 多分类贝叶斯模型  \n",
    "- MultiOutputClassifier将单类预测模型转换为多类模型，类似于一个模型只预测一个类"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建多标签分类模型\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultiOutputClassifier(MultinomialNB()).fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "### 训练结果 \n",
    "- 平均预测精度只有0.53"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5262782984217439"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,clf.predict(X_test))"
   ]
  },
  {
   "source": [
    "## XGBoost模型  \n",
    "- 训练太过耗时，未得出结果我就终止了训练\n",
    "- 因为每个y_train都是一个37维的向量，因此需要训练37个模型，加之训练集太大，导致训练时间非常长，而且如果要调参的话，时间就更长了"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV,KFold\n",
    "import xgboost as xgb "
   ]
  },
  {
   "source": [
    "model = MultiOutputClassifier( xgb.XGBClassifier(n_jobs = -1))\n",
    "model.fit(X_train, y_train)\n",
    "accuracy_score(y_test,model.predict(X_test))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# 深度学习模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['text'].iloc[:100000], data_label[:100000],test_size = 0.15,random_state = 1)"
   ]
  },
  {
   "source": [
    "## 分词与embedding  \n",
    "- Tokenizer使用方法：[链接](https://zhuanlan.zhihu.com/p/138054335)\n",
    "[链接](https://zhuanlan.zhihu.com/p/65192903)\n",
    "- 本文使用的tensorflow2.3.0版本"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "max_features= 500#最大分词数\n",
    "max_len= 150#最大截取截取长度\n",
    "embed_size=100#\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "tokens = Tokenizer(num_words = max_features)\n",
    "tokens.fit_on_texts(list(x_train))\n",
    "\n",
    "#y_train = data_label[:100000]\n",
    "x_sub_train = tokens.texts_to_sequences(x_train)\n",
    "x_sub_train = sequence.pad_sequences(x_sub_train, maxlen=max_len)\n",
    "\n"
   ]
  },
  {
   "source": [
    "- 将每个text都转换为了一个150维的向量"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((85000, 150), (85000,))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "x_sub_train.shape,x_train.shape"
   ]
  },
  {
   "source": [
    "## 定义模型并训练"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "from tensorflow.keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D# Keras Callback Functions:\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "532/532 [==============================] - 1139s 2s/step - loss: 0.1034 - accuracy: 0.4690 - val_loss: 0.0705 - val_accuracy: 0.6457\n",
      "Epoch 2/5\n",
      "  7/532 [..............................] - ETA: 16:59 - loss: 0.0724 - accuracy: 0.6127"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(max_len, ))\n",
    "x = Embedding(max_features, embed_size, trainable=True)(sequence_input)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool]) \n",
    "preds = Dense(38, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])\n",
    "model.fit(x_sub_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          validation_split=0.2,\n",
    "          epochs=epochs)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}